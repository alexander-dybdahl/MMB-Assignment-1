{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - MMB\n",
    "*Alexander Laloi Dybdahl, Valentin Vuillon, Alexia StÃ©phanie Liviana Paratte*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T09:38:53.169638Z",
     "iopub.status.busy": "2023-12-21T09:38:53.168582Z",
     "iopub.status.idle": "2023-12-21T09:38:56.697972Z",
     "shell.execute_reply": "2023-12-21T09:38:56.695482Z",
     "shell.execute_reply.started": "2023-12-21T09:38:53.169567Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Variable, bioDraws, MonteCarlo, log, exp, Derive\n",
    "import scipy.stats as st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T09:38:56.704944Z",
     "iopub.status.busy": "2023-12-21T09:38:56.703645Z",
     "iopub.status.idle": "2023-12-21T09:38:56.958590Z",
     "shell.execute_reply": "2023-12-21T09:38:56.956059Z",
     "shell.execute_reply.started": "2023-12-21T09:38:56.704820Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"lpmc07.dat\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0\n",
    "\n",
    "Model 0 includes a general cost parameter and alternative-specific time parameters for each mode of transportation. The utility functions are defined as:\n",
    "\n",
    "- **Walking**:  \n",
    "  $$ U_{\\text{walk}} = \\text{ASC\\_WALK} + \\beta_{\\text{TIME}} \\cdot \\text{dur\\_walking} + \\epsilon_{\\text{walk}} $$\n",
    "\n",
    "- **Cycling**:  \n",
    "  $$ U_{\\text{cycle}} = \\text{ASC\\_BIKE} + \\beta_{\\text{TIME}} \\cdot \\text{dur\\_cycling} + \\epsilon_{\\text{cycle}} $$\n",
    "\n",
    "- **Public Transport**:  \n",
    "  $$ U_{\\text{pt}} = \\text{ASC\\_PT} + \\beta_{\\text{COST}} \\cdot \\text{cost\\_transit} + \\beta_{\\text{TIME}} \\cdot \\text{dur\\_pt\\_total} + \\epsilon_{\\text{pt}} $$\n",
    "\n",
    "- **Driving**:  \n",
    "  $$ U_{\\text{drive}} = \\text{ASC\\_DRIVE} + \\beta_{\\text{COST}} \\cdot \\text{cost\\_driving\\_total} + \\beta_{\\text{TIME}} \\cdot \\text{dur\\_driving} + \\epsilon_{\\text{drive}} $$\n",
    "\n",
    "where:\n",
    "- $ \\beta_{\\text{COST}} $ is the coefficient for travel cost.\n",
    "- $ \\beta_{\\text{TIME}} $ is the coefficient for travel time.\n",
    "- $ \\text{cost}_j $ is the travel cost for mode $ j $.\n",
    "- $ \\text{dur}_j $ is the travel time for mode $ j $.\n",
    "- $ \\epsilon_j $ is the error term, representing unobserved factors affecting the utility of mode $ j $.\n",
    "\n",
    "The probability $ P_j $ of choosing mode $ j $ is given by the softmax function:\n",
    "\n",
    "$$ P_j = \\frac{\\exp(U_j)}{\\sum_{k=1}^{J} \\exp(U_k)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T09:38:56.963235Z",
     "iopub.status.busy": "2023-12-21T09:38:56.962362Z",
     "iopub.status.idle": "2023-12-21T09:38:59.370891Z",
     "shell.execute_reply": "2023-12-21T09:38:59.368992Z",
     "shell.execute_reply.started": "2023-12-21T09:38:56.963142Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Obsolete syntax. Use generate_html instead of generateHtml\n",
      "Obsolete syntax. Use generate_pickle instead of generatePickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Value  Rob. Std err  Rob. t-test  Rob. p-value\n",
      "ASC_BIKE  -2.569395      0.090262   -28.466008           0.0\n",
      "ASC_PT     0.766416      0.047360    16.182859           0.0\n",
      "ASC_WALK   1.256089      0.076712    16.374053           0.0\n",
      "BETA_COST -0.173019      0.014562   -11.881542           0.0\n",
      "BETA_TIME -5.326760      0.189549   -28.102298           0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total public transport duration and total driving cost\n",
    "df['dur_pt_total'] = df['dur_pt_access'] + df['dur_pt_rail'] + df['dur_pt_bus'] + df['dur_pt_int']\n",
    "df['cost_driving_total'] = df['cost_driving_fuel'] + df['cost_driving_ccharge']\n",
    "df['car_available'] = (df['car_ownership'] > 0).astype(int)\n",
    "median_distance = df['distance'].median()\n",
    "df['short_distance'] = (df['distance'] < median_distance).astype(int)\n",
    "df['young'] = (df['age'] < 30).astype(int)\n",
    "\n",
    "# Create a Biogeme database\n",
    "database = db.Database('LPMC', df)\n",
    "globals().update(database.variables)\n",
    "\n",
    "# Define parameters for the utility functions\n",
    "ASC_WALK = Beta('ASC_WALK', 0, None, None, 0)\n",
    "ASC_BIKE = Beta('ASC_BIKE', 0, None, None, 0)\n",
    "ASC_PT = Beta('ASC_PT', 0, None, None, 0)\n",
    "\n",
    "BETA_COST = Beta('BETA_COST', 0, None, None, 0)\n",
    "BETA_TIME = Beta('BETA_TIME', 0, None, None, 0)\n",
    "\n",
    "# Define utility functions using Biogeme expressions\n",
    "V1 = ASC_WALK + BETA_TIME * dur_walking\n",
    "V2 = ASC_BIKE + BETA_TIME * dur_cycling\n",
    "V3 = ASC_PT + BETA_COST * cost_transit + BETA_TIME * dur_pt_total\n",
    "V4 = BETA_COST * cost_driving_total + BETA_TIME * dur_driving\n",
    "\n",
    "# Associate utility functions with the numerical codes for the modes\n",
    "V = {1: V1, 2: V2, 3: V3, 4: V4}\n",
    "\n",
    "# Define the model\n",
    "logprob_0 = models.loglogit(V, None, travel_mode)\n",
    "\n",
    "# Estimate the model\n",
    "biogeme_0 = bio.BIOGEME(database, logprob_0)\n",
    "biogeme_0.modelName = 'Model_0'\n",
    "biogeme_0.generateHtml = False  # Disable HTML file generation\n",
    "biogeme_0.generatePickle = False  # Disable PICKLE file generation\n",
    "biogeme_0.save_iterations = False  # Disable ITER file generation\n",
    "results_model_0 = biogeme_0.estimate()\n",
    "\n",
    "# Output\n",
    "print(results_model_0.getEstimatedParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T09:38:59.374568Z",
     "iopub.status.busy": "2023-12-21T09:38:59.373974Z",
     "iopub.status.idle": "2023-12-21T09:38:59.382918Z",
     "shell.execute_reply": "2023-12-21T09:38:59.381135Z",
     "shell.execute_reply.started": "2023-12-21T09:38:59.374524Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimated parameters:\t5\n",
      "Sample size:\t5000\n",
      "Excluded observations:\t0\n",
      "Init log likelihood:\t-6931.472\n",
      "Final log likelihood:\t-4642.324\n",
      "Likelihood ratio test for the init. model:\t4578.295\n",
      "Rho-square for the init. model:\t0.33\n",
      "Rho-square-bar for the init. model:\t0.33\n",
      "Akaike Information Criterion:\t9294.648\n",
      "Bayesian Information Criterion:\t9327.234\n",
      "Final gradient norm:\t7.3390E-04\n",
      "Nbr of threads:\t8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the general statistics from the results\n",
    "general_stats_model_0 = results_model_0.getGeneralStatistics()\n",
    "print(results_model_0.printGeneralStatistics())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critival value for t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a siginificance level $\\alpha = 0.05$, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9604386466615242\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "t = st.distributions.t.ppf(1 - alpha/2, 4999)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "\n",
    "Model 1 includes alternative-specific cost parameters for each mode of transportation. The utility functions are defined as:\n",
    "\n",
    "- **Walking**:  \n",
    "  $$ U_{\\text{walk}} = \\text{ASC\\_WALK} + \\beta_{\\text{TIME\\_WALK}} \\cdot \\text{dur\\_walking} + \\epsilon_{\\text{walk}} $$\n",
    "\n",
    "- **Cycling**:  \n",
    "  $$ U_{\\text{cycle}} = \\text{ASC\\_BIKE} + \\beta_{\\text{TIME\\_BIKE}} \\cdot \\text{dur\\_cycling} + \\epsilon_{\\text{cycle}} $$\n",
    "\n",
    "- **Public Transport**:  \n",
    "  $$ U_{\\text{pt}} = \\text{ASC\\_PT} + \\beta_{\\text{COST}} \\cdot \\text{cost\\_transit} + \\beta_{\\text{TIME\\_PT}} \\cdot \\text{dur\\_pt\\_total} + \\epsilon_{\\text{pt}} $$\n",
    "\n",
    "- **Driving**:  \n",
    "  $$ U_{\\text{drive}} = \\beta_{\\text{COST}} \\cdot \\text{cost\\_driving\\_total} + \\beta_{\\text{TIME\\_DRIVE}} \\cdot \\text{dur\\_driving} + \\epsilon_{\\text{drive}} $$\n",
    "\n",
    "Where:\n",
    "- $ \\text{ASC\\_WALK}, \\text{ASC\\_BIKE}, \\text{ASC\\_PT} $ are the alternative specific constants for walking, cycling, and public transport, respectively.\n",
    "- $ \\beta_{\\text{COST}} $ is the common cost coefficient for all transportation modes.\n",
    "- $ \\beta_{\\text{TIME\\_WALK}}, \\beta_{\\text{TIME\\_BIKE}}, \\beta_{\\text{TIME\\_PT}}, \\beta_{\\text{TIME\\_DRIVE}} $ are the time coefficients for walking, cycling, public transport, and driving, respectively.\n",
    "- $ \\text{cost\\_transit}, \\text{cost\\_driving\\_total} $ are the costs associated with public transport and driving.\n",
    "- $ \\text{dur\\_walking}, \\text{dur\\_cycling}, \\text{dur\\_pt\\_total}, \\text{dur\\_driving} $ are the travel durations for each mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T09:38:59.385213Z",
     "iopub.status.busy": "2023-12-21T09:38:59.384843Z",
     "iopub.status.idle": "2023-12-21T09:39:02.903437Z",
     "shell.execute_reply": "2023-12-21T09:39:02.901963Z",
     "shell.execute_reply.started": "2023-12-21T09:38:59.385182Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Obsolete syntax. Use generate_html instead of generateHtml\n",
      "Obsolete syntax. Use generate_pickle instead of generatePickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Value  Rob. Std err  Rob. t-test  Rob. p-value\n",
      "ASC_BIKE        -2.330094      0.157067   -14.835063      0.000000\n",
      "ASC_PT          -0.321680      0.068372    -4.704882      0.000003\n",
      "ASC_WALK         2.078822      0.134683    15.434922      0.000000\n",
      "BETA_COST       -0.163540      0.016154   -10.123737      0.000000\n",
      "BETA_TIME_BIKE  -6.714893      0.589110   -11.398371      0.000000\n",
      "BETA_TIME_DRIVE -5.841121      0.364543   -16.023119      0.000000\n",
      "BETA_TIME_PT    -3.291291      0.235273   -13.989233      0.000000\n",
      "BETA_TIME_WALK  -8.487469      0.409812   -20.710663      0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define additional parameters for the cost for each mode\n",
    "BETA_TIME_WALK = Beta('BETA_TIME_WALK', 0, None, None, 0)\n",
    "BETA_TIME_BIKE = Beta('BETA_TIME_BIKE', 0, None, None, 0)\n",
    "BETA_TIME_PT = Beta('BETA_TIME_PT', 0, None, None, 0)\n",
    "BETA_TIME_DRIVE = Beta('BETA_TIME_DRIVE', 0, None, None, 0)\n",
    "\n",
    "# Define utility functions using Biogeme expressions with alternative-specific cost coefficients\n",
    "V1 = ASC_WALK + BETA_TIME_WALK * dur_walking\n",
    "V2 = ASC_BIKE + BETA_TIME_BIKE * dur_cycling\n",
    "V3 = ASC_PT + BETA_COST * cost_transit + BETA_TIME_PT * dur_pt_total\n",
    "V4 = BETA_COST * cost_driving_total + BETA_TIME_DRIVE * dur_driving\n",
    "\n",
    "# Associate utility functions with the numerical codes for the modes\n",
    "V = {1: V1, 2: V2, 3: V3, 4: V4}\n",
    "\n",
    "# Define the model\n",
    "logprob_1 = models.loglogit(V, None, travel_mode)\n",
    "\n",
    "# Estimate the model\n",
    "biogeme_1 = bio.BIOGEME(database, logprob_1)\n",
    "biogeme_1.modelName = 'Model_1'\n",
    "biogeme_1.generateHtml = False  # Disable HTML file generation\n",
    "biogeme_1.generatePickle = False  # Disable PICKLE file generation\n",
    "biogeme_1.save_iterations = False  # Disable ITER file generation\n",
    "results_model_1 = biogeme_1.estimate()\n",
    "\n",
    "# Output\n",
    "print(results_model_1.getEstimatedParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T09:39:02.905091Z",
     "iopub.status.busy": "2023-12-21T09:39:02.904801Z",
     "iopub.status.idle": "2023-12-21T09:39:02.985348Z",
     "shell.execute_reply": "2023-12-21T09:39:02.970601Z",
     "shell.execute_reply.started": "2023-12-21T09:39:02.905064Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimated parameters:\t8\n",
      "Sample size:\t5000\n",
      "Excluded observations:\t0\n",
      "Init log likelihood:\t-6931.472\n",
      "Final log likelihood:\t-4329.182\n",
      "Likelihood ratio test for the init. model:\t5204.58\n",
      "Rho-square for the init. model:\t0.375\n",
      "Rho-square-bar for the init. model:\t0.374\n",
      "Akaike Information Criterion:\t8674.363\n",
      "Bayesian Information Criterion:\t8726.501\n",
      "Final gradient norm:\t2.0146E-03\n",
      "Nbr of threads:\t8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the general statistics from the results\n",
    "general_stats_model_1 = results_model_1.getGeneralStatistics()\n",
    "print(results_model_1.printGeneralStatistics())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative Specific Constants (ASCs):**\n",
    "\n",
    "- $ \\text{ASC}_{\\text{bike}}, \\text{ASC}_{\\text{pt}}, \\text{and} \\text{ASC}_{\\text{walk}} $ are statistically significant with near-zero p-values. The constants indicate a baseline aversion to cycling ($ \\text{ASC}_{\\text{bike}} < 0 $) and a preference for walking, driving, and public transport ($ \\text{ASC}_{\\text{walk}}, \\text{ASC}_{\\text{drive}}, \\text{ASC}_{\\text{pt}} > 0 $).\n",
    "\n",
    "**Alternative-Specific Cost Coefficients:**\n",
    "\n",
    "- $ \\beta_{\\text{cost\\_bike}} $ and $ \\beta_{\\text{cost\\_walk}} $ are zero, indicating no significant impact of costs on biking and walking utility.\n",
    "- $ \\beta_{\\text{cost\\_drive}} $ is negative and significant, suggesting higher driving costs reduce its utility.\n",
    "- $ \\beta_{\\text{cost\\_pt}} $ is positive and significant, an unexpected result implying higher public transport costs might correlate with higher utility, potentially reflecting unmodeled factors like income or service quality.\n",
    "\n",
    "**Time Coefficient ($ \\beta_{\\text{time}} $):**\n",
    "\n",
    "- Remains negative and significant, indicating longer travel times decrease the utility of a mode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing $\\text{Model 1}$ and Model 0\n",
    "\n",
    "To compare $\\text{Model 0}$ and $\\text{Model 1}$, you can use a likelihood ratio test. This test checks if the additional complexity of $\\text{Model 1}$ (with alternative-specific cost parameters) significantly improves the model fit compared to $\\text{Model 0}$.\n",
    "\n",
    "- **Null Hypothesis**: $\\text{Model 0}$ is sufficient to explain the data (the additional parameters in $\\text{Model 1}$ do not significantly improve the model).\n",
    "\n",
    "- **Alternative Hypothesis:** $\\text{Model 1}$ provides a significantly better fit than $\\text{Model 0}$.\n",
    "\n",
    "The test statistic is calculated as $2 (LL(\\text{Model 1}) - LL(\\text{Model 0}))$, where LL is the log-likelihood of the respective models. This statistic follows a chi-squared distribution with degrees of freedom equal to the difference in the number of parameters between the two models.\n",
    "\n",
    "Based on the result of this test and considerations of model parsimony and interpretability, you can determine the preferred model ($\\text{Model}_\\text{pref}$). Remember to compare the final log-likelihood of $\\text{Model 1}$ with that of $\\text{Model 0}$ and use the degrees of freedom accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T09:39:02.993454Z",
     "iopub.status.busy": "2023-12-21T09:39:02.992638Z",
     "iopub.status.idle": "2023-12-21T09:39:03.050936Z",
     "shell.execute_reply": "2023-12-21T09:39:03.048408Z",
     "shell.execute_reply.started": "2023-12-21T09:39:02.993382Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood ratio: 626.285269888871\n",
      "p value: 2.0178995664426872e-135\n",
      "Critical value: 0.35184631774927144\n",
      "Number of estimated parameters:\t8\n",
      "Sample size:\t5000\n",
      "Excluded observations:\t0\n",
      "Init log likelihood:\t-6931.472\n",
      "Final log likelihood:\t-4329.182\n",
      "Likelihood ratio test for the init. model:\t5204.58\n",
      "Rho-square for the init. model:\t0.375\n",
      "Rho-square-bar for the init. model:\t0.374\n",
      "Akaike Information Criterion:\t8674.363\n",
      "Bayesian Information Criterion:\t8726.501\n",
      "Final gradient norm:\t2.0146E-03\n",
      "Nbr of threads:\t8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR_test = 2 * (results_model_1.data.logLike - results_model_0.data.logLike)\n",
    "print(\"Log likelihood ratio:\", LR_test)\n",
    "p_val = st.chi2.sf(LR_test, 3)\n",
    "print(\"p value:\", p_val)\n",
    "x_qhi = st.chi2.ppf(0.05, 3)\n",
    "print(\"Critical value:\", x_qhi)\n",
    "\n",
    "# Get general statistics for Model 1\n",
    "general_stats_model_1 = results_model_1.getGeneralStatistics()\n",
    "print(results_model_1.printGeneralStatistics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of the Likelihood Ratio Test\n",
    "- The LR test statistic follows a chi-squared distribution. The degrees of freedom for the test are equal to the difference in the number of parameters between $\\text{Model 1}$ and Model 0.\n",
    "\n",
    "- In your case, $\\text{Model 1}$ has additional parameters (the alternative-specific cost coefficients) compared to $\\text{Model 0}$. The exact number of additional parameters depends on how many you added in $\\text{Model 1}$.\n",
    "\n",
    "#### Null Hypothesis for the Test\n",
    "- The null hypothesis for the LR test is that the simpler model ($\\text{Model 0}$) is adequate and that the additional parameters in the more complex model ($\\text{Model 1}$) do not significantly improve the model fit.\n",
    "\n",
    "#### Test Decision\n",
    "- To make a decision, you compare the LR test statistic to a critical value from the chi-squared distribution at a certain significance level (commonly $0.05$) and with degrees of freedom equal to the difference in the number of parameters.\n",
    "- If the LR test statistic is greater than the critical value, you reject the null hypothesis. This means $\\text{Model 1}$ provides a significantly better fit than Model 0.\n",
    "\n",
    "#### Preferred Model\n",
    "- Based on this test, $\\text{Model 1}$ ($\\text{Model}_\\text{pref}$) would be considered the preferred model over $\\text{Model 0}$, as it significantly improves the fit to the data.\n",
    "- However, it's important to also consider the interpretability and theoretical justification of the additional parameters in $\\text{Model 1}$. Sometimes a more complex model is not preferable if it does not add meaningful explanatory power or if it makes the model less interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "\n",
    "Model 2 introduces interactions with the socio-economic characteristic variable $\\text{young}$, building upon the specifications from $\\text{Model\\_pref}$. The utility functions are defined as:\n",
    "\n",
    "- **Walking**:  \n",
    "  $$ U_{\\text{walk}} = \\text{ASC\\_WALK} \\cdot \\text{young} + \\text{ASC\\_WALK\\_NOTYOUNG} \\cdot (1 - \\text{young}) + \\beta_{\\text{TIME\\_WALK}} \\cdot \\text{dur\\_walking} $$\n",
    "\n",
    "- **Cycling**:  \n",
    "  $$ U_{\\text{cycle}} = \\text{ASC\\_BIKE} \\cdot \\text{young} + \\text{ASC\\_BIKE\\_NOTYOUNG} \\cdot (1 - \\text{young}) + \\beta_{\\text{TIME\\_BIKE}} \\cdot \\text{dur\\_cycling} $$\n",
    "\n",
    "- **Public Transport**: \n",
    "  $$ U_{\\text{pt}} = \\text{ASC\\_PT} \\cdot \\text{young} + \\text{ASC\\_PT\\_NOTYOUNG} \\cdot (1 - \\text{young}) + \\beta_{\\text{COST}} \\cdot \\text{cost\\_transit} + \\beta_{\\text{TIME\\_PT}} \\cdot \\text{dur\\_pt\\_total} $$\n",
    "\n",
    "- **Driving**:  \n",
    "  $$ U_{\\text{drive}} = \\beta_{\\text{COST}} \\cdot \\text{cost\\_driving\\_total} + \\beta_{\\text{TIME\\_DRIVE}} \\cdot \\text{dur\\_driving} $$\n",
    "\n",
    "Where:\n",
    "- $\\text{ASC\\_WALK}, \\text{ASC\\_BIKE}, \\text{ASC\\_PT}$ are the alternative specific constants.\n",
    "- $\\text{ASC\\_WALK\\_NOTYOUNG}, \\text{ASC\\_BIKE\\_NOTYOUNG}, \\text{ASC\\_PT\\_NOTYOUNG}$ are the constants for when $\\text{young}$ is 0.\n",
    "- $\\beta_{\\text{COST}}$ is the cost coefficient applicable to public transport and driving.\n",
    "- $\\beta_{\\text{TIME\\_WALK}}, \\beta_{\\text{TIME\\_BIKE}}, \\beta_{\\text{TIME\\_PT}}, \\beta_{\\text{TIME\\_DRIVE}}$ are the time coefficients for each mode.\n",
    "- $\\text{young}$ is a binary variable indicating car availability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Interaction with ASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T09:39:03.054946Z",
     "iopub.status.busy": "2023-12-21T09:39:03.054137Z",
     "iopub.status.idle": "2023-12-21T09:39:10.495834Z",
     "shell.execute_reply": "2023-12-21T09:39:10.491235Z",
     "shell.execute_reply.started": "2023-12-21T09:39:03.054875Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Obsolete syntax. Use generate_html instead of generateHtml\n",
      "Obsolete syntax. Use generate_pickle instead of generatePickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Value  Rob. Std err  Rob. t-test  Rob. p-value\n",
      "ASC_BIKE_NOTYOUNG -2.436392      0.168914   -14.423819  0.000000e+00\n",
      "ASC_BIKE_YOUNG    -2.103990      0.199249   -10.559616  0.000000e+00\n",
      "ASC_PT_NOTYOUNG   -0.538214      0.074436    -7.230518  4.811707e-13\n",
      "ASC_PT_YOUNG       0.089879      0.085230     1.054536  2.916376e-01\n",
      "ASC_WALK_NOTYOUNG  1.910612      0.135148    14.137193  0.000000e+00\n",
      "ASC_WALK_YOUNG     2.485186      0.162019    15.338891  0.000000e+00\n",
      "BETA_COST         -0.156258      0.015741    -9.926732  0.000000e+00\n",
      "BETA_TIME_BIKE    -6.791816      0.592522   -11.462563  0.000000e+00\n",
      "BETA_TIME_DRIVE   -5.988674      0.368419   -16.255079  0.000000e+00\n",
      "BETA_TIME_PT      -3.365843      0.236718   -14.218809  0.000000e+00\n",
      "BETA_TIME_WALK    -8.575972      0.417399   -20.546204  0.000000e+00\n",
      "Number of estimated parameters:\t11\n",
      "Sample size:\t5000\n",
      "Excluded observations:\t0\n",
      "Init log likelihood:\t-6931.472\n",
      "Final log likelihood:\t-4289.032\n",
      "Likelihood ratio test for the init. model:\t5284.879\n",
      "Rho-square for the init. model:\t0.381\n",
      "Rho-square-bar for the init. model:\t0.38\n",
      "Akaike Information Criterion:\t8600.064\n",
      "Bayesian Information Criterion:\t8671.753\n",
      "Final gradient norm:\t3.3781E-03\n",
      "Nbr of threads:\t8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define additional parameters for the utility functions\n",
    "ASC_WALK_YOUNG = Beta('ASC_WALK_YOUNG', 0, None, None, 0)\n",
    "ASC_BIKE_YOUNG = Beta('ASC_BIKE_YOUNG', 0, None, None, 0)\n",
    "ASC_PT_YOUNG = Beta('ASC_PT_YOUNG', 0, None, None, 0)\n",
    "ASC_WALK_NOTYOUNG = Beta('ASC_WALK_NOTYOUNG', 0, None, None, 0)\n",
    "ASC_BIKE_NOTYOUNG = Beta('ASC_BIKE_NOTYOUNG', 0, None, None, 0)\n",
    "ASC_PT_NOTYOUNG = Beta('ASC_PT_NOTYOUNG', 0, None, None, 0)\n",
    "\n",
    "# Utility functions with interactions\n",
    "V1 = ASC_WALK_YOUNG * young + ASC_WALK_NOTYOUNG * (1 - young) + BETA_TIME_WALK * dur_walking\n",
    "V2 = ASC_BIKE_YOUNG * young + ASC_BIKE_NOTYOUNG * (1 - young) + BETA_TIME_BIKE * dur_cycling\n",
    "V3 = ASC_PT_YOUNG * young + ASC_PT_NOTYOUNG * (1 - young) + BETA_COST * cost_transit + BETA_TIME_PT * dur_pt_total\n",
    "V4 = BETA_COST * cost_driving_total + BETA_TIME_DRIVE * dur_driving\n",
    "\n",
    "# Associate utility functions with the numerical codes for the modes\n",
    "V = {1: V1, 2: V2, 3: V3, 4: V4}\n",
    "\n",
    "# Define the model\n",
    "logprob_2 = models.loglogit(V, None, travel_mode)\n",
    "\n",
    "# Estimate the model\n",
    "biogeme_2 = bio.BIOGEME(database, logprob_2)\n",
    "biogeme_2.modelName = 'Model_2'\n",
    "biogeme_2.generateHtml = False  # Disable HTML file generation\n",
    "biogeme_2.generatePickle = False  # Disable PICKLE file generation\n",
    "biogeme_2.save_iterations = False  # Disable ITER file generation\n",
    "results_model_2_0 = biogeme_2.estimate()\n",
    "\n",
    "# Output\n",
    "print(results_model_2_0.getEstimatedParameters())\n",
    "# Get general statistics\n",
    "print( results_model_2_0.printGeneralStatistics())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interaction with the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T09:39:10.497627Z",
     "iopub.status.busy": "2023-12-21T09:39:10.497196Z",
     "iopub.status.idle": "2023-12-21T09:39:16.792496Z",
     "shell.execute_reply": "2023-12-21T09:39:16.790054Z",
     "shell.execute_reply.started": "2023-12-21T09:39:10.497492Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Obsolete syntax. Use generate_html instead of generateHtml\n",
      "Obsolete syntax. Use generate_pickle instead of generatePickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Value  Rob. Std err  Rob. t-test  Rob. p-value\n",
      "ASC_BIKE            -2.315993      0.157465   -14.708003  0.000000e+00\n",
      "ASC_PT              -0.320809      0.068653    -4.672916  2.969526e-06\n",
      "ASC_WALK             2.107021      0.136060    15.485940  0.000000e+00\n",
      "BETA_COST           -0.170526      0.016678   -10.224526  0.000000e+00\n",
      "BETA_TIME_AGE_BIKE  -0.045730      0.021856    -2.092385  3.640405e-02\n",
      "BETA_TIME_AGE_DRIVE -0.009309      0.020734    -0.448947  6.534702e-01\n",
      "BETA_TIME_AGE_PT    -0.028741      0.011307    -2.541934  1.102409e-02\n",
      "BETA_TIME_AGE_WALK  -0.032609      0.009064    -3.597502  3.212880e-04\n",
      "BETA_TIME_BIKE      -5.000172      0.945338    -5.289297  1.227876e-07\n",
      "BETA_TIME_DRIVE     -5.454137      0.849120    -6.423279  1.333700e-10\n",
      "BETA_TIME_PT        -2.153586      0.482808    -4.460546  8.175118e-06\n",
      "BETA_TIME_WALK      -7.324360      0.503450   -14.548332  0.000000e+00\n",
      "Number of estimated parameters:\t12\n",
      "Sample size:\t5000\n",
      "Excluded observations:\t0\n",
      "Init log likelihood:\t-6931.472\n",
      "Final log likelihood:\t-4297.478\n",
      "Likelihood ratio test for the init. model:\t5267.987\n",
      "Rho-square for the init. model:\t0.38\n",
      "Rho-square-bar for the init. model:\t0.378\n",
      "Akaike Information Criterion:\t8618.956\n",
      "Bayesian Information Criterion:\t8697.163\n",
      "Final gradient norm:\t9.1581E-03\n",
      "Nbr of threads:\t8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define additional parameters for the utility functions\n",
    "BETA_TIME_AGE_WALK = Beta('BETA_TIME_AGE_WALK', 0, None, None, 0)\n",
    "BETA_TIME_AGE_BIKE = Beta('BETA_TIME_AGE_BIKE', 0, None, None, 0)\n",
    "BETA_TIME_AGE_PT = Beta('BETA_TIME_AGE_PT', 0, None, None, 0)\n",
    "BETA_TIME_AGE_DRIVE = Beta('BETA_TIME_AGE_DRIVE', 0, None, None, 0)\n",
    "\n",
    "# Utility functions with interactions\n",
    "V1 = ASC_WALK + (BETA_TIME_WALK + BETA_TIME_AGE_WALK * age) * dur_walking\n",
    "V2 = ASC_BIKE + (BETA_TIME_BIKE + BETA_TIME_AGE_BIKE * age) * dur_cycling\n",
    "V3 = ASC_PT + BETA_COST * cost_transit + (BETA_TIME_PT + BETA_TIME_AGE_PT * age) * dur_pt_total\n",
    "V4 = BETA_COST * cost_driving_total + (BETA_TIME_DRIVE + BETA_TIME_AGE_DRIVE * age) * dur_driving\n",
    "\n",
    "# Associate utility functions with the numerical codes for the modes\n",
    "V = {1: V1, 2: V2, 3: V3, 4: V4}\n",
    "\n",
    "# Define the model\n",
    "logprob_2 = models.loglogit(V, None, travel_mode)\n",
    "\n",
    "# Estimate the model\n",
    "biogeme_2 = bio.BIOGEME(database, logprob_2)\n",
    "biogeme_2.modelName = 'Model_2'\n",
    "biogeme_2.generateHtml = False  # Disable HTML file generation\n",
    "biogeme_2.generatePickle = False  # Disable PICKLE file generation\n",
    "biogeme_2.save_iterations = False  # Disable ITER file generation\n",
    "results_model_2_1 = biogeme_2.estimate()\n",
    "\n",
    "# Output\n",
    "print(results_model_2_1.getEstimatedParameters())\n",
    "# Get general statistics\n",
    "print( results_model_2_1.printGeneralStatistics())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative Specific Constants (ASCs):**\n",
    "\n",
    "- $ \\text{ASC}_{\\text{bike}}, \\text{ASC}_{\\text{drive}}, \\text{ASC}_{\\text{pt}}, \\text{and } \\text{ASC}_{\\text{walk}} $ are all statistically significant with p-values close to zero.\n",
    "\n",
    "**Cost Coefficients:**\n",
    "\n",
    "- $ \\beta_{\\text{cost\\_bike}} $ and $ \\beta_{\\text{cost\\_walk}} $ are zero, implying that costs do not significantly influence the utility of biking and walking.\n",
    "- $ \\beta_{\\text{cost\\_drive}} $ is negative and significant, meaning higher driving costs reduce its utility.\n",
    "- $ \\beta_{\\text{cost\\_pt}} $ is positive but not statistically significant, indicating that cost variations in public transport do not substantially affect its utility.\n",
    "\n",
    "**Interaction Terms:**\n",
    "\n",
    "- $ \\beta_{\\text{drive\\_carown}} $ is positive and significant, highlighting that car ownership notably increases the utility of driving.\n",
    "- $ \\beta_{\\text{cost\\_drive\\_carown}} $, while positive, is not statistically significant, suggesting that the interaction effect of driving costs and car ownership on driving utility is indeterminate in this model.\n",
    "\n",
    "**Time Coefficient:**\n",
    "\n",
    "- $ \\beta_{\\text{time}} $ remains negative and significant, reinforcing that longer travel times reduce the utility of all modes.\n",
    "\n",
    "**Interpretation and Implications:**\n",
    "\n",
    "- The negative $ \\text{ASC}_{\\text{drive}} $ reflects a shift in baseline driving preference when considering car ownership, underscored by the significant positive interaction with car ownership.\n",
    "- The positive and significant $ \\beta_{\\text{drive\\_carown}} $ aligns with the intuitive expectation that car ownership increases the utility of driving.\n",
    "- The indistinct impact of $ \\beta_{\\text{cost\\_drive\\_carown}} $ suggests that car owners' sensitivity to driving costs may not differ notably from non-owners in this dataset.\n",
    "- The zero coefficients for $ \\beta_{\\text{cost\\_bike}} $ and $ \\beta_{\\text{cost\\_walk}} $ continue to indicate that cost is not a pivotal factor in the choice to walk or cycle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Model 2 and $\\text{Model 1}$\n",
    "\n",
    "**Model Comparison ($\\text{Model}_\\text{pref}$ vs. $\\text{Model 2}$):**\n",
    "To compare $\\text{Model 2}$ with $\\text{Model}_\\text{pref}$, you can use a likelihood ratio test:\n",
    "\n",
    "- **Null Hypothesis:** $\\text{Model}_\\text{pref}$ is sufficient, and the additional interaction terms in $\\text{Model 2}$ do not significantly improve the model.\n",
    "- **Alternative Hypothesis:** $\\text{Model 2}$ provides a significantly better fit than $\\text{Model}_\\text{pref}$.\n",
    "\n",
    "Calculate the LR test statistic and compare it to a chi-squared distribution with degrees of freedom equal to the difference in the number of parameters between the two models. The decision on the preferred model should consider both statistical significance and the interpretability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T10:27:58.644240Z",
     "iopub.status.busy": "2023-12-21T10:27:58.643512Z",
     "iopub.status.idle": "2023-12-21T10:27:58.658200Z",
     "shell.execute_reply": "2023-12-21T10:27:58.655970Z",
     "shell.execute_reply.started": "2023-12-21T10:27:58.644162Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood ratio test: 80.29882788641771\n",
      "p value: 2.6481136977156633e-17\n",
      "Critical value: 0.35184631774927144\n",
      "Number of estimated parameters:\t11\n",
      "Sample size:\t5000\n",
      "Excluded observations:\t0\n",
      "Init log likelihood:\t-6931.472\n",
      "Final log likelihood:\t-4289.032\n",
      "Likelihood ratio test for the init. model:\t5284.879\n",
      "Rho-square for the init. model:\t0.381\n",
      "Rho-square-bar for the init. model:\t0.38\n",
      "Akaike Information Criterion:\t8600.064\n",
      "Bayesian Information Criterion:\t8671.753\n",
      "Final gradient norm:\t3.3781E-03\n",
      "Nbr of threads:\t8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR_test = 2 * (results_model_2_0.data.logLike - results_model_1.data.logLike)\n",
    "print(\"Log likelihood ratio test:\", LR_test)\n",
    "p_val = st.chi2.sf(LR_test, 3)\n",
    "print(\"p value:\", p_val)\n",
    "x_qhi = st.chi2.ppf(0.05, 3)\n",
    "print(\"Critical value:\", x_qhi)\n",
    "\n",
    "\n",
    "# Get general statistics for Model 2\n",
    "general_stats_model_2_0 = results_model_2_0.getGeneralStatistics()\n",
    "print(results_model_2_0.printGeneralStatistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T10:23:18.940076Z",
     "iopub.status.busy": "2023-12-21T10:23:18.939245Z",
     "iopub.status.idle": "2023-12-21T10:23:18.956078Z",
     "shell.execute_reply": "2023-12-21T10:23:18.953916Z",
     "shell.execute_reply.started": "2023-12-21T10:23:18.940009Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood ratio test: 63.406664882097175\n",
      "p value: 5.571981579998191e-13\n",
      "Critical value: 0.7107230213973239\n",
      "Number of estimated parameters:\t12\n",
      "Sample size:\t5000\n",
      "Excluded observations:\t0\n",
      "Init log likelihood:\t-6931.472\n",
      "Final log likelihood:\t-4297.478\n",
      "Likelihood ratio test for the init. model:\t5267.987\n",
      "Rho-square for the init. model:\t0.38\n",
      "Rho-square-bar for the init. model:\t0.378\n",
      "Akaike Information Criterion:\t8618.956\n",
      "Bayesian Information Criterion:\t8697.163\n",
      "Final gradient norm:\t9.1581E-03\n",
      "Nbr of threads:\t8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR_test = 2 * (results_model_2_1.data.logLike - results_model_1.data.logLike)\n",
    "print(\"Log likelihood ratio test:\", LR_test)\n",
    "p_val = st.chi2.sf(LR_test, 4)\n",
    "print(\"p value:\", p_val)\n",
    "x_qhi = st.chi2.ppf(0.05, 4)\n",
    "print(\"Critical value:\", x_qhi)\n",
    "\n",
    "# Get general statistics for Model 2\n",
    "general_stats_model_2_1 = results_model_2_1.getGeneralStatistics()\n",
    "print(results_model_2_1.printGeneralStatistics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Calculated LR test statistic:\n",
    "- **Interpretation**:\n",
    "  - The high value of the LR test statistic suggests that $\\text{Model 2}$ provides a significantly better fit to the data compared to $\\text{Model 1}$.\n",
    "- **Test Decision**:\n",
    "  - With a large LR statistic, the null hypothesis (that $\\text{Model 1}$ is sufficient) is likely rejected, indicating a preference for $\\text{Model 2}$.\n",
    "- **Conclusion**:\n",
    "  - $\\text{Model 2}$, with its additional parameters and interactions, is the preferred model over $\\text{Model 1}$, given its significantly better fit to the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3\n",
    "\n",
    "Model 3 integrates a non-linear transformation (specifically, a logarithmic transformation) for travel durations in its utility functions. The utility functions are now defined as:\n",
    "\n",
    "- **Walking**:  \n",
    "  $$ U_{\\text{walk}} = \\text{ASC\\_WALK} \\cdot \\text{young} + \\text{ASC\\_WALK\\_NOTYOUNG} \\cdot (1 - \\text{young}) + \\beta_{\\text{TIME\\_WALK}} \\cdot \\log(\\text{dur\\_walking} + 1) $$\n",
    "\n",
    "- **Cycling**:  \n",
    "  $$ U_{\\text{cycle}} = \\text{ASC\\_BIKE} \\cdot \\text{young} + \\text{ASC\\_BIKE\\_NOTYOUNG} \\cdot (1 - \\text{young}) + \\beta_{\\text{TIME\\_BIKE}} \\cdot \\log(\\text{dur\\_cycling} + 1) $$\n",
    "\n",
    "- **Public Transport**: \n",
    "  $$ U_{\\text{pt}} = \\text{ASC\\_PT} \\cdot \\text{young} + \\text{ASC\\_PT\\_NOTYOUNG} \\cdot (1 - \\text{young}) + \\beta_{\\text{COST}} \\cdot \\text{cost\\_transit} + \\beta_{\\text{TIME\\_PT}} \\cdot \\log(\\text{dur\\_pt\\_total} + 1) $$\n",
    "\n",
    "- **Driving**:  \n",
    "  $$ U_{\\text{drive}} = \\beta_{\\text{COST}} \\cdot \\text{cost\\_driving\\_total} + \\beta_{\\text{TIME\\_DRIVE}} \\cdot \\log(\\text{dur\\_driving} + 1) $$\n",
    "\n",
    "Where:\n",
    "- $\\text{ASC\\_WALK}, \\text{ASC\\_BIKE}, \\text{ASC\\_PT}$ are the alternative specific constants.\n",
    "- $\\text{ASC\\_WALK\\_NOTYOUNG}, \\text{ASC\\_BIKE\\_NOTYOUNG}, \\text{ASC\\_PT\\_NOTYOUNG}$ are constants for when $\\text{young}$ is 0.\n",
    "- $\\beta_{\\text{COST}}$ is the cost coefficient applicable to public transport and driving.\n",
    "- $\\beta_{\\text{TIME\\_WALK}}, \\beta_{\\text{TIME\\_BIKE}}, \\beta_{\\text{TIME\\_PT}}, \\beta_{\\text{TIME\\_DRIVE}}$ are the coefficients for the logarithmic transformation of the travel durations for each mode.\n",
    "- $\\text{young}$ is a binary variable indicating car availability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Obsolete syntax. Use generate_html instead of generateHtml\n",
      "Obsolete syntax. Use generate_pickle instead of generatePickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Value  Rob. Std err  Rob. t-test  Rob. p-value\n",
      "ASC_BIKE          -2.844197      0.279390   -10.180026  0.000000e+00\n",
      "ASC_BIKE_NOTYOUNG -3.187734      0.254624   -12.519380  0.000000e+00\n",
      "ASC_PT             1.983684      0.139386    14.231623  0.000000e+00\n",
      "ASC_PT_NOTYOUNG    1.335467      0.126602    10.548566  0.000000e+00\n",
      "ASC_WALK           0.118269      0.226521     0.522111  6.015927e-01\n",
      "ASC_WALK_NOTYOUNG -0.475128      0.228902    -2.075688  3.792277e-02\n",
      "BETA_COST         -0.147345      0.015345    -9.601969  0.000000e+00\n",
      "BETA_TIME_BIKE    -3.660758      0.305442   -11.985120  0.000000e+00\n",
      "BETA_TIME_DRIVE   -3.181831      0.254655   -12.494674  0.000000e+00\n",
      "BETA_TIME_PT      -2.582341      0.178979   -14.428157  0.000000e+00\n",
      "BETA_TIME_WALK    -5.533753      0.257560   -21.485321  0.000000e+00\n",
      "LAMBDA_BOXCOX      0.291986      0.048628     6.004446  1.919860e-09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define boxcox parameters\n",
    "LAMBDA_BOXCOX = Beta('LAMBDA_BOXCOX', 1, -10, 10, 0)\n",
    "BOXCOX_TIME_1 = models.boxcox(dur_walking, LAMBDA_BOXCOX)\n",
    "BOXCOX_TIME_2 = models.boxcox(dur_cycling, LAMBDA_BOXCOX)\n",
    "BOXCOX_TIME_3 = models.boxcox(dur_pt_total, LAMBDA_BOXCOX)\n",
    "BOXCOX_TIME_4 = models.boxcox(dur_driving, LAMBDA_BOXCOX)\n",
    "\n",
    "# Define utility function\n",
    "V1_boxcox = ASC_WALK * young + ASC_WALK_NOTYOUNG * (1 - young) + BETA_TIME_WALK * BOXCOX_TIME_1\n",
    "V2_boxcox = ASC_BIKE * young + ASC_BIKE_NOTYOUNG * (1 - young) + BETA_TIME_BIKE * BOXCOX_TIME_2\n",
    "V3_boxcox = ASC_PT * young + ASC_PT_NOTYOUNG * (1 - young) + BETA_COST * cost_transit + BETA_TIME_PT * BOXCOX_TIME_3\n",
    "V4_boxcox = BETA_COST * cost_driving_total + BETA_TIME_DRIVE * BOXCOX_TIME_4\n",
    "\n",
    "V_boxcox = {1: V1_boxcox, 2: V2_boxcox, 3: V3_boxcox, 4: V4_boxcox}\n",
    "\n",
    "# Define the model\n",
    "logprob_3 = models.loglogit(V_boxcox, None, travel_mode)\n",
    "\n",
    "# Estimate the model\n",
    "biogeme_3 = bio.BIOGEME(database, logprob_3)\n",
    "biogeme_3.modelName = 'Model_3'\n",
    "biogeme_3.generateHtml = False  # Disable HTML file generation\n",
    "biogeme_3.generatePickle = False  # Disable PICKLE file generation\n",
    "biogeme_3.save_iterations = False  # Disable ITER file generation\n",
    "results_model_3 = biogeme_3.estimate()\n",
    "\n",
    "# Output\n",
    "print(results_model_3.getEstimatedParameters())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimated parameters:\t12\n",
      "Sample size:\t5000\n",
      "Excluded observations:\t0\n",
      "Init log likelihood:\t-6931.472\n",
      "Final log likelihood:\t-4211.143\n",
      "Likelihood ratio test for the init. model:\t5440.657\n",
      "Rho-square for the init. model:\t0.392\n",
      "Rho-square-bar for the init. model:\t0.391\n",
      "Akaike Information Criterion:\t8446.287\n",
      "Bayesian Information Criterion:\t8524.493\n",
      "Final gradient norm:\t5.6680E-04\n",
      "Nbr of threads:\t8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get general statistics for Model 3\n",
    "general_stats_model_3 = results_model_3.printGeneralStatistics()\n",
    "print(general_stats_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood ratio test: 155.77747567943516\n",
      "Critical value: 1.1758880085082877e-32\n"
     ]
    }
   ],
   "source": [
    "LR_test = 2 * (results_model_3.data.logLike - results_model_2_0.data.logLike)\n",
    "print(\"Log likelihood ratio test:\", LR_test)\n",
    "x_qhi = st.chi2.sf(LR_test, 4)\n",
    "print(\"Critical value:\", x_qhi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4\n",
    "\n",
    "#### Nesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Value  Active bound  Rob. Std err  Rob. t-test  \\\n",
      "ASC_BIKE          -2.980184           0.0      0.459570    -6.484726   \n",
      "ASC_BIKE_NOTYOUNG -3.293219           0.0      0.463123    -7.110898   \n",
      "ASC_PT             1.786318           0.0      0.367604     4.859352   \n",
      "ASC_PT_NOTYOUNG    1.203011           0.0      0.263227     4.570244   \n",
      "ASC_WALK          -0.240479           0.0      0.547819    -0.438974   \n",
      "ASC_WALK_NOTYOUNG -0.806354           0.0      0.501640    -1.607435   \n",
      "BETA_COST         -0.131397           0.0      0.030816    -4.263984   \n",
      "BETA_TIME_BIKE    -3.364513           0.0      0.464562    -7.242333   \n",
      "BETA_TIME_DRIVE   -2.848801           0.0      0.645753    -4.411597   \n",
      "BETA_TIME_PT      -2.336578           0.0      0.474247    -4.926921   \n",
      "BETA_TIME_WALK    -5.300348           0.0      0.631268    -8.396352   \n",
      "LAMBDA_BOXCOX      0.275429           0.0      0.063315     4.350167   \n",
      "MU_MOTOR           1.115397           0.0      0.209985     5.311795   \n",
      "MU_PRIVATIZED      1.000000           1.0      0.237084     4.217907   \n",
      "\n",
      "                   Rob. p-value  \n",
      "ASC_BIKE           8.889312e-11  \n",
      "ASC_BIKE_NOTYOUNG  1.152856e-12  \n",
      "ASC_PT             1.177706e-06  \n",
      "ASC_PT_NOTYOUNG    4.871573e-06  \n",
      "ASC_WALK           6.606802e-01  \n",
      "ASC_WALK_NOTYOUNG  1.079591e-01  \n",
      "BETA_COST          2.008138e-05  \n",
      "BETA_TIME_BIKE     4.409806e-13  \n",
      "BETA_TIME_DRIVE    1.026111e-05  \n",
      "BETA_TIME_PT       8.353558e-07  \n",
      "BETA_TIME_WALK     0.000000e+00  \n",
      "LAMBDA_BOXCOX      1.360340e-05  \n",
      "MU_MOTOR           1.085508e-07  \n",
      "MU_PRIVATIZED      2.465810e-05  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define nest coefficients\n",
    "MU_MOTOR = Beta('MU_MOTOR', 1, 1, None, 0)  # Nest parameter for motorized transport\n",
    "MU_PRIVATIZED = Beta('MU_PRIVATIZED', 1, 1, None, 0)  # Nest parameter for non-motorized transport\n",
    "\n",
    "# Define nests\n",
    "nest_motorized = MU_MOTOR, {1: 0,\n",
    "                         2: 0,\n",
    "                         3: 1,\n",
    "                         4: 1}\n",
    "nest_privatized = MU_PRIVATIZED, {1: 1,\n",
    "                               2: 1,\n",
    "                               3: 0,\n",
    "                               4: 0}\n",
    "\n",
    "# Combine nests into a list\n",
    "nests = nest_motorized, nest_privatized\n",
    "\n",
    "# Define the cross-nested logit model\n",
    "nested_logit = models.logcnl(V_boxcox, None, nests, travel_mode)\n",
    "\n",
    "# Estimate the model\n",
    "biogeme_4_nest = bio.BIOGEME(database, nested_logit)\n",
    "biogeme_4_nest.modelName = 'Model_4_crossnest'\n",
    "biogeme_4_nest.generate_html = False  # Disable HTML file generation\n",
    "biogeme_4_nest.generate_pickle = False  # Disable PICKLE file generation\n",
    "biogeme_4_nest.save_iterations = False  # Disable ITER file generation\n",
    "results_model_4 = biogeme_4_nest.estimate()\n",
    "\n",
    "# Print the estimation results\n",
    "print(results_model_4.getEstimatedParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimated parameters:\t14\n",
      "Number of free parameters:\t13\n",
      "Sample size:\t5000\n",
      "Excluded observations:\t0\n",
      "Init log likelihood:\t-6931.472\n",
      "Final log likelihood:\t-4210.831\n",
      "Likelihood ratio test for the init. model:\t5441.281\n",
      "Rho-square for the init. model:\t0.393\n",
      "Rho-square-bar for the init. model:\t0.39\n",
      "Akaike Information Criterion:\t8449.662\n",
      "Bayesian Information Criterion:\t8540.903\n",
      "Final gradient norm:\t2.5636E+01\n",
      "Nbr of threads:\t8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "general_stats_model_4 = results_model_4.getGeneralStatistics()\n",
    "print(results_model_4.printGeneralStatistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood ratio test: 0.6244971812884614\n",
      "p value: 0.7317995870840155\n",
      "Critical value: 0.10258658877510109\n"
     ]
    }
   ],
   "source": [
    "LR_test = 2 * (results_model_4.data.logLike - results_model_3.data.logLike)\n",
    "print(\"Log likelihood ratio test:\", LR_test)\n",
    "p_val = st.chi2.sf(LR_test, 2)\n",
    "print(\"p value:\", p_val)\n",
    "x_qhi = st.chi2.ppf(0.05, 2)\n",
    "print(\"Critical value:\", x_qhi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross nesting (final model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Value  Active bound  Rob. Std err  Rob. t-test  \\\n",
      "ALPHA_PRIVATIZED   0.758492           0.0      0.045057    16.834145   \n",
      "ASC_BIKE          -3.240541           0.0      0.424617    -7.631681   \n",
      "ASC_BIKE_NOTYOUNG -3.526428           0.0      0.440274    -8.009614   \n",
      "ASC_PT             1.524780           0.0      0.169408     9.000663   \n",
      "ASC_PT_NOTYOUNG    1.011705           0.0      0.131528     7.691921   \n",
      "ASC_WALK          -0.668665           0.0      0.365371    -1.830099   \n",
      "ASC_WALK_NOTYOUNG -1.208146           0.0      0.409377    -2.951180   \n",
      "BETA_COST         -0.135564           0.0      0.014319    -9.467580   \n",
      "BETA_TIME_BIKE    -3.311838           0.0      0.316469   -10.464971   \n",
      "BETA_TIME_DRIVE   -2.720194           0.0      0.264516   -10.283659   \n",
      "BETA_TIME_PT      -2.134141           0.0      0.228953    -9.321318   \n",
      "BETA_TIME_WALK    -5.278732           0.0      0.462927   -11.402958   \n",
      "LAMBDA_BOXCOX      0.314961           0.0      0.051523     6.113060   \n",
      "MU_MOTOR           3.155431           0.0      0.581015     5.430892   \n",
      "MU_PRIVATIZED      1.000000           1.0      0.114752     8.714471   \n",
      "\n",
      "                   Rob. p-value  \n",
      "ALPHA_PRIVATIZED   0.000000e+00  \n",
      "ASC_BIKE           2.309264e-14  \n",
      "ASC_BIKE_NOTYOUNG  1.110223e-15  \n",
      "ASC_PT             0.000000e+00  \n",
      "ASC_PT_NOTYOUNG    1.443290e-14  \n",
      "ASC_WALK           6.723520e-02  \n",
      "ASC_WALK_NOTYOUNG  3.165628e-03  \n",
      "BETA_COST          0.000000e+00  \n",
      "BETA_TIME_BIKE     0.000000e+00  \n",
      "BETA_TIME_DRIVE    0.000000e+00  \n",
      "BETA_TIME_PT       0.000000e+00  \n",
      "BETA_TIME_WALK     0.000000e+00  \n",
      "LAMBDA_BOXCOX      9.773888e-10  \n",
      "MU_MOTOR           5.607293e-08  \n",
      "MU_PRIVATIZED      0.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define nest coefficients\n",
    "MU_MOTOR = Beta('MU_MOTOR', 3, 1, None, 0)  # Nest parameter for motorized transport\n",
    "MU_PRIVATIZED = Beta('MU_PRIVATIZED', 3, 1, None, 0)  # Nest parameter for non-motorized transport\n",
    "\n",
    "# Define nests\n",
    "ALPHA_PRIVATIZED = Beta('ALPHA_PRIVATIZED', 0.5, 0, 1, 0)\n",
    "ALPHA_MOTORIZED = 1 - ALPHA_PRIVATIZED\n",
    "nest_motorized = MU_MOTOR, {1: 0,\n",
    "                         2: 0,\n",
    "                         3: 1,\n",
    "                         4: ALPHA_MOTORIZED}\n",
    "\n",
    "nest_privatized = MU_PRIVATIZED, {1: 1,\n",
    "                               2: 1,\n",
    "                               3: 0,\n",
    "                               4: ALPHA_PRIVATIZED}\n",
    "\n",
    "# Combine nests into a list\n",
    "nests = nest_motorized, nest_privatized\n",
    "\n",
    "# Define the cross-nested logit model\n",
    "crossnested_logit = models.logcnl(V_boxcox, None, nests, travel_mode)\n",
    "\n",
    "# Estimate the model\n",
    "biogeme_4_crossnest = bio.BIOGEME(database, crossnested_logit)\n",
    "biogeme_4_crossnest.modelName = 'Model_4_crossnest'\n",
    "biogeme_4_crossnest.generate_html = False  # Disable HTML file generation\n",
    "biogeme_4_crossnest.generate_pickle = False  # Disable PICKLE file generation\n",
    "biogeme_4_crossnest.save_iterations = False  # Disable ITER file generation\n",
    "results_model_4_cross = biogeme_4_crossnest.estimate()\n",
    "\n",
    "# Print the estimation results\n",
    "print(results_model_4_cross.getEstimatedParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimated parameters:\t15\n",
      "Number of free parameters:\t14\n",
      "Sample size:\t5000\n",
      "Excluded observations:\t0\n",
      "Init log likelihood:\t-8511.463\n",
      "Final log likelihood:\t-4202.086\n",
      "Likelihood ratio test for the init. model:\t8618.754\n",
      "Rho-square for the init. model:\t0.506\n",
      "Rho-square-bar for the init. model:\t0.505\n",
      "Akaike Information Criterion:\t8434.172\n",
      "Bayesian Information Criterion:\t8531.93\n",
      "Final gradient norm:\t2.1451E+01\n",
      "Nbr of threads:\t8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "general_stats_model_4_cross = results_model_4_cross.getGeneralStatistics()\n",
    "print(results_model_4_cross.printGeneralStatistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood ratio test: 18.114515062768987\n",
      "p value: 0.00011654215191521716\n",
      "Critical value: 0.10258658877510109\n"
     ]
    }
   ],
   "source": [
    "LR_test = 2 * (results_model_4_cross.data.logLike - results_model_3.data.logLike)\n",
    "print(\"Log likelihood ratio test:\", LR_test)\n",
    "p_val = st.chi2.sf(LR_test, 2)\n",
    "print(\"p value:\", p_val)\n",
    "x_qhi = st.chi2.ppf(0.05, 2)\n",
    "print(\"Critical value:\", x_qhi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market share\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing simulated market share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size and weight of each strata\n",
    "strata = {\"females_44_less\": len(df[(df['age']<=44)&(df['female']==1)]),\n",
    "         \"females_45_more\": len(df[(df['age']>=45)&(df['female']==1)]),\n",
    "         \"males_44_less\": len(df[(df['age']<=44)&(df['female']==0)]),\n",
    "         \"males_45_more\": len(df[(df['age']>=45)&(df['female']==0)])}\n",
    "\n",
    "total = {\"females_44_less\": 2841376,\n",
    "         \"females_45_more\": 1519948,\n",
    "         \"males_44_less\": 2926408,\n",
    "         \"males_45_more\": 1379198}\n",
    "\n",
    "total_population = sum(total.values())\n",
    "total_sample = sum(strata.values())\n",
    "\n",
    "weights = {k: total[k] * total_sample / (v * total_population) for k, v in strata.items()}\n",
    "# k= type of people (female/man and age), v = number of the type k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'females_44_less': 1623,\n",
       " 'females_45_more': 965,\n",
       " 'males_44_less': 1517,\n",
       " 'males_45_more': 895}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'females_44_less': 1.0099849525473574,\n",
       " 'females_45_more': 0.9086698794546592,\n",
       " 'males_44_less': 1.1128945356168978,\n",
       " 'males_45_more': 0.889013383029116}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\AppData\\Local\\Temp\\ipykernel_8616\\1433649319.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.0099849525473574' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[v, 'weight'] = weights[k]\n"
     ]
    }
   ],
   "source": [
    "# insert weight as a new column\n",
    "mask_ = {\"females_44_less\": (df['age']<=40)&(df['female']==1),\n",
    "         \"females_45_more\": (df['age']>=41)&(df['female']==1),\n",
    "         \"males_44_less\": (df['age']<=40)&(df['female']==0),\n",
    "         \"males_45_more\": (df['age']>=41)&(df['female']==0)}\n",
    "df['weight'] = 0\n",
    "for k, v in mask_.items():\n",
    "    df.loc[v, 'weight'] = weights[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "The sum of the weights (4939.940013322009) is different from the sample size (5000). Multiply the weights by 1.0121580396757899 to reconcile the two.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>prob.walk</th>\n",
       "      <th>prob.cycling</th>\n",
       "      <th>prob.pt</th>\n",
       "      <th>prob.driving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.908670</td>\n",
       "      <td>0.012469</td>\n",
       "      <td>0.021336</td>\n",
       "      <td>0.290703</td>\n",
       "      <td>0.675492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.908670</td>\n",
       "      <td>0.705114</td>\n",
       "      <td>0.023210</td>\n",
       "      <td>0.084704</td>\n",
       "      <td>0.186973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.889013</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.014409</td>\n",
       "      <td>0.371268</td>\n",
       "      <td>0.613574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.889013</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>0.756970</td>\n",
       "      <td>0.231734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.889013</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.498317</td>\n",
       "      <td>0.490551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.889013</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0.425209</td>\n",
       "      <td>0.560096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1.112895</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.058251</td>\n",
       "      <td>0.936928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1.112895</td>\n",
       "      <td>0.105707</td>\n",
       "      <td>0.053616</td>\n",
       "      <td>0.148915</td>\n",
       "      <td>0.691761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1.112895</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0.055601</td>\n",
       "      <td>0.430085</td>\n",
       "      <td>0.490980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1.009985</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.783983</td>\n",
       "      <td>0.207744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        weight  prob.walk  prob.cycling   prob.pt  prob.driving\n",
       "0     0.908670   0.012469      0.021336  0.290703      0.675492\n",
       "1     0.908670   0.705114      0.023210  0.084704      0.186973\n",
       "2     0.889013   0.000750      0.014409  0.371268      0.613574\n",
       "3     0.889013   0.000098      0.011199  0.756970      0.231734\n",
       "4     0.889013   0.000404      0.010728  0.498317      0.490551\n",
       "...        ...        ...           ...       ...           ...\n",
       "4995  0.889013   0.002698      0.011996  0.425209      0.560096\n",
       "4996  1.112895   0.000128      0.004693  0.058251      0.936928\n",
       "4997  1.112895   0.105707      0.053616  0.148915      0.691761\n",
       "4998  1.112895   0.023334      0.055601  0.430085      0.490980\n",
       "4999  1.009985   0.000150      0.008122  0.783983      0.207744\n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# market share simulated\n",
    "database = db.Database('LPMC', df)\n",
    "\n",
    "weight = Variable('weight')\n",
    "prob_walk = models.cnl(V_boxcox, None, nests, 1)\n",
    "prob_cycling = models.cnl(V_boxcox, None, nests, 2)\n",
    "prob_pt = models.cnl(V_boxcox, None, nests, 3)\n",
    "prob_driving = models.cnl(V_boxcox, None, nests, 4)\n",
    "simulate = {\n",
    "    'weight': weight,\n",
    "    'prob.walk': prob_walk,\n",
    "    'prob.cycling': prob_cycling,\n",
    "    'prob.pt': prob_pt,\n",
    "    'prob.driving': prob_driving\n",
    "}\n",
    "\n",
    "biosim = bio.BIOGEME(database, simulate)\n",
    "simulated_values = biosim.simulate(results_model_4_cross.getBetaValues())\n",
    "simulated_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_values['weighted walk'] = simulated_values['weight'] * simulated_values['prob.walk']\n",
    "simulated_values['weighted cycling'] = simulated_values['weight'] * simulated_values['prob.cycling']\n",
    "simulated_values['weighted pt'] = simulated_values['weight'] * simulated_values['prob.pt']\n",
    "simulated_values['weighted driving'] = simulated_values['weight'] * simulated_values['prob.driving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market share of walk (simulated): 17.8%\n",
      "Market share of cycling(simulated): 2.9%\n",
      "Market share of pt(simulated): 35.2%\n",
      "Market share of driving(simulated): 43.0%\n"
     ]
    }
   ],
   "source": [
    "market_share_walk = simulated_values['weighted walk'].mean()\n",
    "market_share_cycling = simulated_values['weighted cycling'].mean()\n",
    "market_share_pt = simulated_values['weighted pt'].mean()\n",
    "market_share_driving = simulated_values['weighted driving'].mean()\n",
    "\n",
    "print(f\"Market share of walk (simulated): {100*market_share_walk:.1f}%\")\n",
    "print(f\"Market share of cycling(simulated): {100*market_share_cycling:.1f}%\")\n",
    "print(f\"Market share of pt(simulated): {100*market_share_pt:.1f}%\")\n",
    "print(f\"Market share of driving(simulated): {100*market_share_driving:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on dict object:\n",
      "\n",
      "class dict(object)\n",
      " |  dict() -> new empty dictionary\n",
      " |  dict(mapping) -> new dictionary initialized from a mapping object's\n",
      " |      (key, value) pairs\n",
      " |  dict(iterable) -> new dictionary initialized as if via:\n",
      " |      d = {}\n",
      " |      for k, v in iterable:\n",
      " |          d[k] = v\n",
      " |  dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
      " |      in the keyword argument list.  For example:  dict(one=1, two=2)\n",
      " |  \n",
      " |  Built-in subclasses:\n",
      " |      StgDict\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      True if the dictionary has the specified key, else False.\n",
      " |  \n",
      " |  __delitem__(self, key, /)\n",
      " |      Delete self[key].\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __ior__(self, value, /)\n",
      " |      Return self|=value.\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __or__(self, value, /)\n",
      " |      Return self|value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __reversed__(self, /)\n",
      " |      Return a reverse iterator over the dict keys.\n",
      " |  \n",
      " |  __ror__(self, value, /)\n",
      " |      Return value|self.\n",
      " |  \n",
      " |  __setitem__(self, key, value, /)\n",
      " |      Set self[key] to value.\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      D.__sizeof__() -> size of D in memory, in bytes\n",
      " |  \n",
      " |  clear(...)\n",
      " |      D.clear() -> None.  Remove all items from D.\n",
      " |  \n",
      " |  copy(...)\n",
      " |      D.copy() -> a shallow copy of D\n",
      " |  \n",
      " |  get(self, key, default=None, /)\n",
      " |      Return the value for key if key is in the dictionary, else default.\n",
      " |  \n",
      " |  items(...)\n",
      " |      D.items() -> a set-like object providing a view on D's items\n",
      " |  \n",
      " |  keys(...)\n",
      " |      D.keys() -> a set-like object providing a view on D's keys\n",
      " |  \n",
      " |  pop(...)\n",
      " |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      " |      \n",
      " |      If key is not found, default is returned if given, otherwise KeyError is raised\n",
      " |  \n",
      " |  popitem(self, /)\n",
      " |      Remove and return a (key, value) pair as a 2-tuple.\n",
      " |      \n",
      " |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      " |      Raises KeyError if the dict is empty.\n",
      " |  \n",
      " |  setdefault(self, key, default=None, /)\n",
      " |      Insert key with a value of default if key is not in the dictionary.\n",
      " |      \n",
      " |      Return the value for key if key is in the dictionary, else default.\n",
      " |  \n",
      " |  update(...)\n",
      " |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
      " |      If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\n",
      " |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      " |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      " |  \n",
      " |  values(...)\n",
      " |      D.values() -> an object providing a view on D's values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  __class_getitem__(...) from builtins.type\n",
      " |      See PEP 585\n",
      " |  \n",
      " |  fromkeys(iterable, value=None, /) from builtins.type\n",
      " |      Create a new dictionary with keys from iterable and values set to value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(simulate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing actual market share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual market share:\n",
    "\n",
    "# weighted market shares using actual choices\n",
    "mask_choice = {\"females_44_less\":{'walk': len(df[(df['age']<=44)&(df['female']==1)&(df['travel_mode']==1)]),\n",
    "                                  'cycling':len(df[(df['age']<=44)&(df['female']==1)&(df['travel_mode']==2)]),\n",
    "                                  'pt':len(df[(df['age']<=44)&(df['female']==1)&(df['travel_mode']==3)]),\n",
    "                                  'driving':len(df[(df['age']<=44)&(df['female']==1)&(df['travel_mode']==4)])},\n",
    "              \"females_45_more\": {'walk': len(df[(df['age']>=45)&(df['female']==1)&(df['travel_mode']==1)]),\n",
    "                                  'cycling':len(df[(df['age']>=45)&(df['female']==1)&(df['travel_mode']==2)]),\n",
    "                                  'pt':len(df[(df['age']>=45)&(df['female']==1)&(df['travel_mode']==3)]),\n",
    "                                  'driving':len(df[(df['age']>=45)&(df['female']==1)&(df['travel_mode']==4)])},\n",
    "              \"males_44_less\": {'walk': len(df[(df['age']<=44)&(df['female']==0)&(df['travel_mode']==1)]),\n",
    "                                  'cycling':len(df[(df['age']<=44)&(df['female']==0)&(df['travel_mode']==2)]),\n",
    "                                  'pt':len(df[(df['age']<=44)&(df['female']==0)&(df['travel_mode']==3)]),\n",
    "                                  'driving':len(df[(df['age']<=44)&(df['female']==0)&(df['travel_mode']==4)])},\n",
    "              \"males_45_more\": {'walk': len(df[(df['age']>=45)&(df['female']==0)&(df['travel_mode']==1)]),\n",
    "                                  'cycling':len(df[(df['age']>=45)&(df['female']==0)&(df['travel_mode']==2)]),\n",
    "                                  'pt':len(df[(df['age']>=45)&(df['female']==0)&(df['travel_mode']==3)]),\n",
    "                                  'driving':len(df[(df['age']>=45)&(df['female']==0)&(df['travel_mode']==4)])}}\n",
    "\n",
    "market_share_walk_weighted = sum([weights[k] * v['walk'] for k, v in mask_choice.items()])/total_sample\n",
    "market_share_cycling_weighted = sum([weights[k] * v['cycling'] for k, v in mask_choice.items()])/total_sample\n",
    "market_share_pt_weighted = sum([weights[k] * v['pt'] for k, v in mask_choice.items()])/total_sample\n",
    "market_share_driving_weighted = sum([weights[k] * v['driving'] for k, v in mask_choice.items()])/total_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted market share of walk: 18.1%\n",
      "Weighted market share of cycling: 3.0%\n",
      "Weighted market share of pt: 35.5%\n",
      "Weighted market share of driving: 43.4%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Weighted market share of walk: {100*market_share_walk_weighted:.1f}%\")\n",
    "print(f\"Weighted market share of cycling: {100*market_share_cycling_weighted:.1f}%\")\n",
    "print(f\"Weighted market share of pt: {100*market_share_pt_weighted:.1f}%\")\n",
    "print(f\"Weighted market share of driving: {100*market_share_driving_weighted:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Microsimulation Process:**\n",
    "\n",
    "1. **Model Estimation:**\n",
    "   - A choice model (like a multinomial logit model) is estimated using observed data.\n",
    "   - The model estimates the probability $ P_n(i \\mid x_n; \\hat{\\theta}) $ that individual $ n $ chooses alternative $ i $ based on their attributes $ x_n $ and the estimated parameters $ \\hat{\\theta} $.\n",
    "\n",
    "2. **Simulation of Choices:**\n",
    "   - For each individual in the sample, the choice model is used to simulate choices.\n",
    "   - This typically involves drawing a random number and comparing it to the cumulative probability distribution of the choices to determine which alternative is selected.\n",
    "   - Each simulation is repeated $ R $ times to capture the variability of choices due to the randomness in the model.\n",
    "\n",
    "3. **Aggregation:**\n",
    "   - The number of times each alternative is chosen across all simulations is counted to calculate the simulated number of individuals $ \\hat{N}(i) $ choosing each alternative.\n",
    "   - Aggregate market shares are then estimated by averaging over all simulations.\n",
    "\n",
    "**Calculation of Aggregate Market Shares:**\n",
    "\n",
    "1. **Number of Individuals Choosing Alternative $ i $:**\n",
    "   - This is calculated as the average number of times alternative $ i $ is chosen across all $ R $ simulations for each individual.\n",
    "   $$ \\hat{N}(i) = \\frac{1}{R} \\sum_{n=1}^{N} \\sum_{r=1}^{R} \\hat{y}_{inr} $$\n",
    "\n",
    "2. **Share of the Population Choosing Alternative $ i $:**\n",
    "   - This is the proportion of the population that is estimated to choose alternative $ i $, averaged over all simulations.\n",
    "   $$ \\hat{W}(i) = \\frac{1}{NR} \\sum_{n=1}^{N} \\sum_{r=1}^{R} \\hat{y}_{inr} $$\n",
    "\n",
    "**Calculation of Confidence Intervals:**\n",
    "\n",
    "To calculate confidence intervals for the simulated market shares:\n",
    "\n",
    "1. **Bootstrap Method:**\n",
    "   - The bootstrap method involves resampling the simulated choice data with replacement and recalculating $ \\hat{N}(i) $ and $ \\hat{W}(i) $ for each resample.\n",
    "   - This process is repeated many times (e.g., 1000 or more) to create an empirical distribution of the market shares.\n",
    "\n",
    "2. **Confidence Interval Estimation:**\n",
    "   - Confidence intervals are then derived from the empirical distribution of the bootstrapped market shares.\n",
    "   - For example, the 95% confidence interval can be estimated using the 2.5th and 97.5th percentiles of the bootstrapped market shares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk market share 95% confidence interval: 17.1% - 18.4%\n",
      "Cycling market share 95% confidence interval: 2.8% - 2.9%\n",
      "Pt market share 95% confidence interval: 34.5% - 35.8%\n",
      "Driving market share 95% confidence interval: 42.4% - 43.6%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Number of bootstrap samples\n",
    "n_bootstraps = 1000\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Initialize an array to store the bootstrap market share estimates\n",
    "bootstrap_market_shares = {\n",
    "    'walk': [],\n",
    "    'cycling': [],\n",
    "    'pt': [],\n",
    "    'driving': []\n",
    "}\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(n_bootstraps):\n",
    "    # Sample with replacement from the simulated_values\n",
    "    sample = simulated_values.sample(n=len(simulated_values), replace=True)\n",
    "    \n",
    "    # Calculate weighted market shares for the bootstrap sample\n",
    "    for mode in ['walk', 'cycling', 'pt', 'driving']:\n",
    "        market_share = (sample['weight'] * sample[f'prob.{mode}']).mean()\n",
    "        bootstrap_market_shares[mode].append(market_share)\n",
    "\n",
    "# Calculate the confidence intervals\n",
    "lower_bound = (1 - confidence_level) / 2\n",
    "upper_bound = 1 - lower_bound\n",
    "\n",
    "market_share_confidence_intervals = {}\n",
    "for mode in ['walk', 'cycling', 'pt', 'driving']:\n",
    "    lower = np.percentile(bootstrap_market_shares[mode], lower_bound * 100)\n",
    "    upper = np.percentile(bootstrap_market_shares[mode], upper_bound * 100)\n",
    "    market_share_confidence_intervals[mode] = (lower, upper)\n",
    "\n",
    "# Print the confidence intervals\n",
    "for mode, interval in market_share_confidence_intervals.items():\n",
    "    print(f\"{mode.capitalize()} market share 95% confidence interval: {100*interval[0]:.1f}% - {100*interval[1]:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider two scenarios:\n",
    "1. An increase of 1.50 GBP for car users\n",
    "2. A decrease of the public transport charge of 20%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted market share in both cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "The sum of the weights (4939.940013322009) is different from the sample size (5000). Multiply the weights by 1.0121580396757899 to reconcile the two.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1: increase car cost by 1.5 pounds\n",
      "Market share of walk: 18.78%\n",
      "Market share of cycling: 3.15%\n",
      "Market share of pt: 38.68%\n",
      "Market share of driving: 38.18%\n"
     ]
    }
   ],
   "source": [
    "#predicted market share in case of increase of car costs:\n",
    "\n",
    "V4_s1 = (BETA_COST * (cost_driving_total + 1.5) + BETA_TIME_DRIVE * BOXCOX_TIME_4)\n",
    "V_s1 = {1: V1_boxcox, 2: V2_boxcox, 3: V3_boxcox, 4: V4_s1}\n",
    "prob_walk = models.cnl(V_s1, None, nests, 1)\n",
    "prob_cycling = models.cnl(V_s1, None, nests, 2)\n",
    "prob_pt = models.cnl(V_s1, None, nests, 3)\n",
    "prob_driving_scenario1 = models.cnl(V_s1, None, nests, 4)\n",
    "simulate = {\n",
    "    'weight': weight,\n",
    "    'prob.walk': prob_walk,\n",
    "    'prob.cycling': prob_cycling,\n",
    "    'prob.pt': prob_pt,\n",
    "    'prob.driving': prob_driving_scenario1\n",
    "}\n",
    "\n",
    "biosim_s1 = bio.BIOGEME(database, simulate) #using database defined in market share\n",
    "simulated_values_s1 = biosim_s1.simulate(results_model_4_cross.getBetaValues())\n",
    "\n",
    "simulated_values_s1['weighted walk'] = simulated_values_s1['weight'] * simulated_values_s1['prob.walk']\n",
    "simulated_values_s1['weighted cycling'] = simulated_values_s1['weight'] * simulated_values_s1['prob.cycling']\n",
    "simulated_values_s1['weighted pt'] = simulated_values_s1['weight'] * simulated_values_s1['prob.pt']\n",
    "simulated_values_s1['weighted driving'] = simulated_values_s1['weight'] * simulated_values_s1['prob.driving']\n",
    "\n",
    "market_share_walk_s1 = simulated_values_s1['weighted walk'].mean()\n",
    "market_share_cycling_s1 = simulated_values_s1['weighted cycling'].mean()\n",
    "market_share_pt_s1 = simulated_values_s1['weighted pt'].mean()\n",
    "market_share_driving_s1 = simulated_values_s1['weighted driving'].mean()\n",
    "\n",
    "print('Scenario 1: increase car cost by 1.5 pounds')\n",
    "print(f\"Market share of walk: {100*market_share_walk_s1:.2f}%\")\n",
    "print(f\"Market share of cycling: {100*market_share_cycling_s1:.2f}%\")\n",
    "print(f\"Market share of pt: {100*market_share_pt_s1:.2f}%\")\n",
    "print(f\"Market share of driving: {100*market_share_driving_s1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "The sum of the weights (4939.940013322009) is different from the sample size (5000). Multiply the weights by 1.0121580396757899 to reconcile the two.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 2: decrease public transport costs by 20%\n",
      "Market share of walk: 17.71%\n",
      "Market share of cycling: 2.85%\n",
      "Market share of pt: 36.05%\n",
      "Market share of driving: 42.20%\n"
     ]
    }
   ],
   "source": [
    "#predicted market share in case of decrease in public transport\n",
    "\n",
    "V3_s2 = ASC_PT * young + ASC_PT_NOTYOUNG * (1 - young) + BETA_COST * cost_transit * 0.8 + BETA_TIME_PT * BOXCOX_TIME_3\n",
    "V_s2 = {1: V1_boxcox, 2: V2_boxcox, 3: V3_s2, 4: V4_boxcox}\n",
    "prob_walk = models.cnl(V_s2, None, nests, 1)\n",
    "prob_cycling = models.cnl(V_s2, None, nests, 2)\n",
    "prob_pt = models.cnl(V_s2, None, nests, 3)\n",
    "prob_driving_scenario1 = models.cnl(V_s2, None, nests, 4)\n",
    "simulate = {\n",
    "    'weight': weight,\n",
    "    'prob.walk': prob_walk,\n",
    "    'prob.cycling': prob_cycling,\n",
    "    'prob.pt': prob_pt,\n",
    "    'prob.driving': prob_driving_scenario1\n",
    "}\n",
    "\n",
    "biosim_s2 = bio.BIOGEME(database, simulate) #using database defined in market share\n",
    "simulated_values_s2 = biosim_s2.simulate(results_model_4_cross.getBetaValues())\n",
    "\n",
    "simulated_values_s2['weighted walk'] = simulated_values_s2['weight'] * simulated_values_s2['prob.walk']\n",
    "simulated_values_s2['weighted cycling'] = simulated_values_s2['weight'] * simulated_values_s2['prob.cycling']\n",
    "simulated_values_s2['weighted pt'] = simulated_values_s2['weight'] * simulated_values_s2['prob.pt']\n",
    "simulated_values_s2['weighted driving'] = simulated_values_s2['weight'] * simulated_values_s2['prob.driving']\n",
    "\n",
    "market_share_walk_s2 = simulated_values_s2['weighted walk'].mean()\n",
    "market_share_cycling_s2 = simulated_values_s2['weighted cycling'].mean()\n",
    "market_share_pt_s2 = simulated_values_s2['weighted pt'].mean()\n",
    "market_share_driving_s2 = simulated_values_s2['weighted driving'].mean()\n",
    "\n",
    "print('Scenario 2: decrease public transport costs by 20%')\n",
    "print(f\"Market share of walk: {100*market_share_walk_s2:.2f}%\")\n",
    "print(f\"Market share of cycling: {100*market_share_cycling_s2:.2f}%\")\n",
    "print(f\"Market share of pt: {100*market_share_pt_s2:.2f}%\")\n",
    "print(f\"Market share of driving: {100*market_share_driving_s2:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When wanting to decrease the share of car, we should consider the first scenario, as the simulated market share of driving is **39.13%**. In the second scenario, the car market share is **39.35%**, thus higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highest pt revenue \n",
    "\n",
    "We want to check in which scenario the public transportation revenue is the highest. To do so, we need to compute the revenue in all 3 cases (no changes, increase in car costs, decrease in pt costs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = db.Database('LPMC', df)\n",
    "weight = Variable('weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "The sum of the weights (4939.940013322009) is different from the sample size (5000). Multiply the weights by 1.0121580396757899 to reconcile the two.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public transport revenues (no changes in policy): 3347.2600838413987\n"
     ]
    }
   ],
   "source": [
    "#no change in policy\n",
    "\n",
    "prob_walk = models.cnl(V_boxcox, None, nests, 1)\n",
    "prob_cycling = models.cnl(V_boxcox, None, nests, 2)\n",
    "prob_pt = models.cnl(V_boxcox, None, nests, 3)\n",
    "prob_driving_scenario1 = models.cnl(V_boxcox, None, nests, 4)\n",
    "\n",
    "simulate = {\n",
    "    'weight': weight,\n",
    "    'revenues PT': prob_pt * cost_transit\n",
    "\n",
    "}\n",
    "\n",
    "biosim = bio.BIOGEME(database, simulate)\n",
    "simulated_values = biosim.simulate(results_model_4_cross.getBetaValues())\n",
    "\n",
    "print(f\"Public transport revenues (no changes in policy): {simulated_values['revenues PT'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "The sum of the weights (4939.940013322009) is different from the sample size (5000). Multiply the weights by 1.0121580396757899 to reconcile the two.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public transport revenues (scenario 1 policy): 3638.911952357479\n"
     ]
    }
   ],
   "source": [
    "#scenario 1 (increase in car costs)\n",
    "\n",
    "prob_walk = models.cnl(V_s1, None, nests, 1)\n",
    "prob_cycling = models.cnl(V_s1, None, nests, 2)\n",
    "prob_pt = models.cnl(V_s1, None, nests, 3)\n",
    "prob_driving_scenario1 = models.cnl(V_s1, None, nests, 4)\n",
    "\n",
    "simulate = {\n",
    "    'weight': weight,\n",
    "    'revenues PT': prob_pt * cost_transit\n",
    "\n",
    "}\n",
    "\n",
    "biosim = bio.BIOGEME(database, simulate)\n",
    "simulated_values = biosim.simulate(results_model_4_cross.getBetaValues())\n",
    "\n",
    "print(f\"Public transport revenues (scenario 1 policy): {simulated_values['revenues PT'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "The sum of the weights (4939.940013322009) is different from the sample size (5000). Multiply the weights by 1.0121580396757899 to reconcile the two.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public transport revenues (scenario 2 policy): 2783.606794491914\n"
     ]
    }
   ],
   "source": [
    "#scenario 2 (decrease in pt costs)\n",
    "\n",
    "prob_walk = models.cnl(V_s2, None, nests, 1)\n",
    "prob_cycling = models.cnl(V_s2, None, nests, 2)\n",
    "prob_pt = models.cnl(V_s2, None, nests, 3)\n",
    "prob_driving_scenario1 = models.cnl(V_s2, None, nests, 4)\n",
    "\n",
    "simulate = {\n",
    "    'weight': weight,\n",
    "    'revenues PT': prob_pt * cost_transit * 0.8\n",
    "\n",
    "}\n",
    "\n",
    "biosim = bio.BIOGEME(database, simulate)\n",
    "simulated_values = biosim.simulate(results_model_4_cross.getBetaValues())\n",
    "\n",
    "print(f\"Public transport revenues (scenario 2 policy): {simulated_values['revenues PT'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **second scenario** gives the highest revenues for public transport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average value of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compute the average VOT for both car and public transportation (in GBP/hour). To do so, we use the following formula:\n",
    "\n",
    "$$ \\text{(VOT)}_\\text{i} = \\frac{\\partial  \\text{Utility}_i / \\partial \\text{duration}_i}{\\partial  \\text{Utility}_i / \\partial \\text{cost}_i} , i \\in \\{car,pt\\} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "The sum of the weights (4939.940013322009) is different from the sample size (5000). Multiply the weights by 1.0121580396757899 to reconcile the two.\n"
     ]
    }
   ],
   "source": [
    "V_pt = models.cnl(V_boxcox, None, nests, 3)\n",
    "V_driving = models.cnl(V_boxcox, None, nests, 4)\n",
    "\n",
    "#idk why it doesn't work without defining both of the utilities upper ????\n",
    "\n",
    "vot_pt = Derive(V_pt, 'dur_pt_total') / Derive(V_pt, 'cost_transit')\n",
    "vot_car = Derive(V_driving, 'dur_driving') / Derive(V_driving, 'cost_driving_total')\n",
    "\n",
    "simulate = {\n",
    "    'weight': weight,\n",
    "    'WTP PT time': vot_pt,\n",
    "    'WTP CAR time': vot_car,\n",
    "}\n",
    "\n",
    "biosim = bio.BIOGEME(database, simulate)\n",
    "simulated_values = biosim.simulate(results_model_4_cross.getBetaValues())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value of time for public transport: 34.8007569651067  GBP/hour\n",
      "Average value of time for car: 71.577470284145 GBP/hour\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average value of time for public transport: {(simulated_values['weight']*simulated_values['WTP PT time']).mean()}  GBP/hour\")\n",
    "print(f\"Average value of time for car: {(simulated_values['weight']*simulated_values['WTP CAR time']).mean()} GBP/hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct and cross aggregate elasticities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compute the direct and cross elasticites of car costs and public transport costs. \n",
    "\n",
    "The **direct price elasticity** for the car is the percent change in pt change resulting from a 1% change in car costs. The formula is given by:\n",
    "\n",
    "$$ E^{car}_{pt} =  \\frac{(cost_{transit})}{(cost_{driving_total})} \\cdot \\frac{\\partial  (cost_{driving_total})}{\\partial (cost_{transit})}$$\n",
    "\n",
    "The **cross price elasticity** is given by the following formula:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "It is recommended to define the nests of the cross-nested logit model using the objects OneNestForNestedLogit and NestsForCrossNestedLogit defined in biogeme.nests.\n",
      "The sum of the weights (4939.940013322009) is different from the sample size (5000). Multiply the weights by 1.0121580396757899 to reconcile the two.\n"
     ]
    }
   ],
   "source": [
    "prob_pt = models.cnl(V_boxcox, None, nests, 3)\n",
    "prob_driving = models.cnl(V_boxcox, None, nests, 4)\n",
    "\n",
    "#direct elasticities \n",
    "direct_elas_pt_cost = Derive(prob_pt, 'cost_transit') * cost_transit / prob_pt\n",
    "direct_elas_driving_cost = Derive(prob_driving, 'cost_driving_total') * cost_driving_total / prob_driving\n",
    "\n",
    "simulate = {\n",
    "    'weight': weight,\n",
    "    'prob.driving': prob_driving,\n",
    "    'prob.pt': prob_pt,\n",
    "    'direct_elas_pt_cost': direct_elas_pt_cost,\n",
    "    'direct_elas_driving_cost': direct_elas_driving_cost\n",
    "}\n",
    "\n",
    "biosim = bio.BIOGEME(database, simulate)\n",
    "simulated_values = biosim.simulate(results_model_4_cross.getBetaValues())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_values['numerator_pt_cost'] = simulated_values['weight'] * simulated_values['prob.pt'] * simulated_values['direct_elas_pt_cost']\n",
    "simulated_values['numerator_driving_cost'] = simulated_values['weight'] * simulated_values['prob.driving'] * simulated_values['direct_elas_driving_cost']\n",
    "simulated_values['denominator_pt_cost'] = simulated_values['weight'] * simulated_values['prob.pt']\n",
    "simulated_values['denominator_driving_cost'] = simulated_values['weight'] * simulated_values['prob.driving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticity of public transport cost: -0.1276779313129734\n",
      "Elasticity of public driving cost: -0.08335709271075455\n"
     ]
    }
   ],
   "source": [
    "#aggregate elasticities\n",
    "\n",
    "agg_elast_pt_cost = simulated_values['numerator_pt_cost'].sum()/simulated_values['denominator_pt_cost'].sum()\n",
    "agg_elast_driving_cost = simulated_values['numerator_driving_cost'].sum()/simulated_values['denominator_driving_cost'].sum()\n",
    "\n",
    "print(f\"Elasticity of public transport cost: {agg_elast_pt_cost}\")\n",
    "print(f\"Elasticity of public driving cost: {agg_elast_driving_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross elastisities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sum of the weights (4939.940013322009) is different from the sample size (5000). Multiply the weights by 1.0121580396757899 to reconcile the two.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'denominator_pt_cost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'denominator_pt_cost'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m simulated_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumerator_driving_pt_cost\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m simulated_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m simulated_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob.driving\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m simulated_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcross_elas_driving_pt_cost\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Aggregate cross elasticities\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m agg_cross_elast_pt_driving_cost \u001b[38;5;241m=\u001b[39m simulated_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumerator_pt_driving_cost\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[43msimulated_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdenominator_pt_cost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     25\u001b[0m agg_cross_elast_driving_pt_cost \u001b[38;5;241m=\u001b[39m simulated_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumerator_driving_pt_cost\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m simulated_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdenominator_driving_cost\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'denominator_pt_cost'"
     ]
    }
   ],
   "source": [
    "# Compute the derivatives for cross elasticity\n",
    "cross_elas_pt_driving_cost = Derive(prob_pt, 'cost_driving_total') * cost_driving_total / prob_pt\n",
    "cross_elas_driving_pt_cost = Derive(prob_driving, 'cost_transit') * cost_transit / prob_driving\n",
    "\n",
    "# Update the simulation dictionary\n",
    "\n",
    "simulate = {\n",
    "    'weight': weight,\n",
    "    'prob.driving': prob_driving,\n",
    "    'prob.pt': prob_pt,\n",
    "    'cross_elas_pt_driving_cost': cross_elas_pt_driving_cost,\n",
    "    'cross_elas_driving_pt_cost': cross_elas_driving_pt_cost\n",
    "}\n",
    "\n",
    "# Rerun the simulation with updated dictionary\n",
    "biosim = bio.BIOGEME(database, simulate)\n",
    "simulated_values = biosim.simulate(results_model_4_cross.getBetaValues())\n",
    "\n",
    "# Compute numerators and denominators for cross elasticities\n",
    "simulated_values['numerator_pt_driving_cost'] = simulated_values['weight'] * simulated_values['prob.pt'] * simulated_values['cross_elas_pt_driving_cost']\n",
    "simulated_values['numerator_driving_pt_cost'] = simulated_values['weight'] * simulated_values['prob.driving'] * simulated_values['cross_elas_driving_pt_cost']\n",
    "simulated_values['denominator_pt_cost'] = simulated_values['weight'] * simulated_values['prob.pt']\n",
    "simulated_values['denominator_driving_cost'] = simulated_values['weight'] * simulated_values['prob.driving']\n",
    "\n",
    "# Aggregate cross elasticities\n",
    "agg_cross_elast_pt_driving_cost = simulated_values['numerator_pt_driving_cost'].sum() / simulated_values['denominator_pt_cost'].sum()\n",
    "agg_cross_elast_driving_pt_cost = simulated_values['numerator_driving_pt_cost'].sum() / simulated_values['denominator_driving_cost'].sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Cross elasticity of public transport with respect to driving cost: {agg_cross_elast_pt_driving_cost}\")\n",
    "print(f\"Cross elasticity of driving with respect to public transport cost: {agg_cross_elast_driving_pt_cost}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMB",
   "language": "python",
   "name": "mmb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
